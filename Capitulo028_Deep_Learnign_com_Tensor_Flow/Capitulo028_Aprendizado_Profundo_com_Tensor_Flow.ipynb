{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d75a25e5",
   "metadata": {
    "id": "d75a25e5"
   },
   "source": [
    "<center> <img src=\"logo_ifba.jpg\" alt=\"jpg_python\" width=\"100\" height=\"\"> </center>\n",
    "<br><br>\n",
    "<center> <img src=\"logo_coext.jpg\" alt=\"jpg_python\" width=\"200\" height=\"\"> </center>\n",
    "<br><br>\n",
    "<center><div style=\"text-align:center\">    <a href=\"https://colab.research.google.com/github/ProfAllanIFBA/Curso_Python_Com_Jupyter_Notebook/blob/main/Capitulo028_Aprendizado_Profundo_com_Tensor_Flow/Capitulo028_Aprendizado_Profundo_com_Tensor_Flow.ipynb\">Link Colab</a> \n",
    "</div><br><br></center>\n",
    "<div align=\"center\"><span style=\"font-size: 26px;\"><strong>Python Com Jupyter Notebook</strong></span></div><br><br>\n",
    "<center> <img src=\"python_gif.gif\" alt=\"gif_python\" width=\"80\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203106bc",
   "metadata": {
    "id": "203106bc"
   },
   "source": [
    "Este material apresenta uma explicação detalhada sobre o uso do software de programação em Python chamado Jupyter Notebook, com foco na análise de dados. Abordaremos desde estruturas básicas, como listas e dicionários, até estruturas mais complexas voltadas para a análise de dados, como pandas e seaborn, além de ferramentas destinadas à inteligência artificial.\n",
    "\n",
    "\n",
    "<font color='red'> <u>Este é um material de uso público e totalmente gratuito</u>. Contudo, eventuais edições são de responsabilidade de quem as fizer. </font>\n",
    "\n",
    "Você pode ajudar a melhorar este material!\n",
    "\n",
    "Contato e Sugestões: allansoares@ifba.edu.br.\n",
    "\n",
    "[**Equipe Executora**](https://github.com/ProfAllanIFBA/Curso_Python_Com_Jupyter_Notebook/blob/main/Capitulo000_Equipe/Capitulo000_Equipe.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e187c412",
   "metadata": {
    "id": "e187c412"
   },
   "source": [
    "<div style=\"border: 2px solid black; padding: 10px; width: 100%; background-color: lightgray; display: flex; align-items: center;\">\n",
    "    <h1 style=\"color: red; text-align: center; margin: auto;\">\n",
    "        Capítulo  28: Aprendizado Profundo com TensorFlow\n",
    "    </h1>\n",
    "</div>\n",
    "\n",
    "<font color='red'></font>\n",
    "<a href=\"\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57946a73",
   "metadata": {
    "id": "57946a73"
   },
   "source": [
    "Iniciaremos este capítulo com um guia detalhado para desenvolver uma rede neural que é capaz de reconhecer imagens pertencentes a dez categorias distintas: *avião, automóvel, pássaro, gato, cachorro, sapo, cavalo, barco* e *caminhão*. Inicialmente, construiremos o modelo utilizando dados provenientes de um banco de dados externo. Posteriormente, avançaremos para uma etapa mais complexa, onde treinaremos o modelo usando dados armazenados localmente, incluindo etapas críticas de preparação e formatação das imagens antes do treinamento. Este tutorial foi desenhado para fornecer uma compreensão abrangente e prática do uso do TensorFlow em aplicações de reconhecimento de imagens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f581354",
   "metadata": {
    "id": "2f581354"
   },
   "source": [
    "## <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 22px;\"><strong>28.1 Exemplo Com Dados Externos</strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c391e89e",
   "metadata": {
    "id": "c391e89e"
   },
   "source": [
    "A seguir, apresentaremos a primeira versão do nosso exemplo. Para isso, utilizaremos dados do CIFAR-10, que serão carregados na memória do nosso sistema. Estes subconjuntos fazem parte do conjunto de dados de 80 milhões de imagens minúsculas e estão rotulados para facilitar o uso em aplicações de aprendizado de máquina. Eles foram coletados e organizados por Alex Krizhevsky, Vinod Nair e Geoffrey Hinton. Mais informações no link: https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4c2815",
   "metadata": {
    "id": "ca4c2815"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>28.1.1 Instalações e Importações Necessárias* </strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3cb07a",
   "metadata": {
    "id": "2b3cb07a"
   },
   "source": [
    "Antes de começar, recomendamos enfaticamente que consulte a documentação oficial do [TensorFlow](https://www.tensorflow.org/) para assegurar a compatibilidade com seu sistema operacional e para estar ciente de possíveis problemas e suas soluções."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5049edb",
   "metadata": {
    "id": "e5049edb"
   },
   "source": [
    "Neste tutorial, utilizaremos a versão 3.11.5 do Jupyter Notebook, específica para sistemas operacionais Windows. A versão necessária pode ser baixada através do seguinte link: https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Windows-x86_64.exe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d022f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:06:58.766639Z",
     "start_time": "2024-03-06T11:06:58.755533Z"
    },
    "id": "b0d022f0"
   },
   "outputs": [],
   "source": [
    "# Versão da linguagem python usada no Jupyter Notebook\n",
    "from platform import python_version\n",
    "\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2710ce6",
   "metadata": {
    "id": "b2710ce6"
   },
   "source": [
    "Além disso usamos a versão  2.12.0 do TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff2e9ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T10:43:50.338873Z",
     "start_time": "2024-03-06T10:43:50.335622Z"
    },
    "id": "eff2e9ac"
   },
   "outputs": [],
   "source": [
    "# Instalando o TensorFlow 2.12.0\n",
    "# !pip install tensorflow==2.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27263f8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T10:43:50.578350Z",
     "start_time": "2024-03-06T10:43:50.575288Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install --upgrade setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb1786",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:07:54.993903Z",
     "start_time": "2024-03-06T11:07:43.661552Z"
    },
    "id": "5bdb1786"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce351da",
   "metadata": {
    "id": "fce351da"
   },
   "source": [
    "Para que tudo corra bem compile a próxima célula e torça para não dar nenhum erro. Em caso de erro explique ao gpt a situação especificando as versões Python e TensorFlow, o sistema operacional etc. Caso não consiga resolver rode pelo colab. Neste último caso você terá que entender sobre endereçamento de pastas na referida plataforma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4db14f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T12:25:10.595931Z",
     "start_time": "2024-03-06T12:25:05.099469Z"
    },
    "id": "b4db14f6"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c930b4ad",
   "metadata": {
    "id": "c930b4ad"
   },
   "source": [
    "<div style=\"width: 50%; height: 4px; background-color: red;\"> <br> <font"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a7045f",
   "metadata": {
    "id": "12a7045f"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>28.1.2 Carregamento e Visualização das Imagens </strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48406c91",
   "metadata": {
    "id": "48406c91"
   },
   "source": [
    "A seguir faremos o carregamento bem como a visualização de algumas figuras disponíveis no banco de dados CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa85302",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:09:37.982655Z",
     "start_time": "2024-03-06T11:09:37.312114Z"
    },
    "id": "afa85302"
   },
   "outputs": [],
   "source": [
    "# Carrega o dataset CIFAR-10\n",
    "(imagens_treino, labels_treino), (imagens_teste, labels_teste) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7387241b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:10:23.943143Z",
     "start_time": "2024-03-06T11:10:23.939151Z"
    },
    "id": "7387241b"
   },
   "outputs": [],
   "source": [
    "# Clases das imagens\n",
    "classes = ['Avião', 'Automóvel', 'Pássaro', 'Gato', 'Cervo',\\\n",
    "           'Cachorro', 'Sapo', 'Cavalo', 'Barco', 'Caminhão']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d5db72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:10:57.981077Z",
     "start_time": "2024-03-06T11:10:57.539366Z"
    },
    "id": "f1d5db72"
   },
   "outputs": [],
   "source": [
    "# Normaliza os valores dos pixels para que os dados fiquem na mesma escala\n",
    "imagens_treino = imagens_treino / 255.0\n",
    "imagens_teste = imagens_teste / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6232c8",
   "metadata": {
    "id": "dc6232c8"
   },
   "source": [
    "*A normalização dos valores dos pixels para uma escala comum é um passo importante no pré-processamento de imagens para redes neurais. Normalmente, os pixels das imagens coloridas em formatos como JPEG ou PNG variam de 0 a 255 (representando a intensidade mínima e máxima, respectivamente, para cada canal de cor). A divisão por 255 é usada para normalizar esses valores para uma escala de 0 a 1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad448461",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:11:13.927970Z",
     "start_time": "2024-03-06T11:11:13.923197Z"
    },
    "id": "ad448461"
   },
   "outputs": [],
   "source": [
    "# Função para exibir as imagens\n",
    "def exibir_imagens(images, labels):\n",
    "    plt.figure(figsize = (10,10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap = plt.cm.binary)\n",
    "        plt.xlabel(classes[labels[i][0]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a170682f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:11:23.844950Z",
     "start_time": "2024-03-06T11:11:23.010554Z"
    },
    "id": "a170682f"
   },
   "outputs": [],
   "source": [
    "# Executa a função\n",
    "exibir_imagens(imagens_treino, labels_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b78f1",
   "metadata": {
    "id": "231b78f1"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>28.1.3 Treinando a Rede Neural </strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9697de60",
   "metadata": {
    "id": "9697de60"
   },
   "source": [
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"cnn.gif\" alt=\"gif_python\" width=\"300\">\n",
    "    <img src=\"carro.jpg\" alt=\"jpg_python\" width=\"700\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727e0bc8",
   "metadata": {
    "id": "727e0bc8"
   },
   "source": [
    "Vejamos o treinamento da nossa rede neuaral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c1a0c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:14:00.359814Z",
     "start_time": "2024-03-06T11:14:00.260215Z"
    },
    "id": "38c1a0c3"
   },
   "outputs": [],
   "source": [
    "# Modelo\n",
    "\n",
    "# Cria o objeto de sequência de camadas\n",
    "modelo_reconhecimento = models.Sequential()\n",
    "\n",
    "# Adiciona o primeiro bloco de convolução e max pooling (camada de entrada)\n",
    "modelo_reconhecimento.add(layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (32, 32, 3)))\n",
    "modelo_reconhecimento.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Adiciona o segundo bloco de convolução e max pooling (camada intermediária)\n",
    "modelo_reconhecimento.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "modelo_reconhecimento.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Adiciona o terceiro bloco de convolução e max pooling (camada intermediária)\n",
    "modelo_reconhecimento.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "modelo_reconhecimento.add(layers.MaxPooling2D((2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c961dcd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:14:35.166429Z",
     "start_time": "2024-03-06T11:14:35.130783Z"
    },
    "id": "c961dcd5"
   },
   "outputs": [],
   "source": [
    "# Adicionar camadas de classificação\n",
    "modelo_reconhecimento.add(layers.Flatten())\n",
    "modelo_reconhecimento.add(layers.Dense(64, activation = 'relu'))\n",
    "modelo_reconhecimento.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1189a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:14:40.137371Z",
     "start_time": "2024-03-06T11:14:40.116059Z"
    },
    "id": "8a1189a6"
   },
   "outputs": [],
   "source": [
    "# Sumário do modelo\n",
    "modelo_reconhecimento.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf754e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:15:15.153557Z",
     "start_time": "2024-03-06T11:15:15.138329Z"
    },
    "id": "ddf754e0"
   },
   "outputs": [],
   "source": [
    "# Compilação do modelo\n",
    "modelo_reconhecimento.compile(optimizer = 'adam',\n",
    "                   loss = 'sparse_categorical_crossentropy',\n",
    "                   metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facc78a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:19:43.326347Z",
     "start_time": "2024-03-06T11:15:24.299523Z"
    },
    "id": "facc78a3"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = modelo_reconhecimento.fit(imagens_treino,\n",
    "                         labels_treino,\n",
    "                         epochs = 10,\n",
    "                         validation_data = (imagens_teste, labels_teste))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be40b4d5",
   "metadata": {
    "id": "be40b4d5"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>28.1.4 Avaliando o Treinamento </strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6231262",
   "metadata": {
    "id": "b6231262"
   },
   "source": [
    "Entramos agora na etapa de verificação do modelo, onde utilizaremos imagens que não foram incluídas nos conjuntos de treino. Para isso, selecionamos algumas imagens e as armazenamos na pasta 'dados_verificacao'. Você é encorajado a adicionar mais imagens a esta pasta, especialmente aquelas que se alinham às categorias abordadas no treinamento do modelo. Essa prática é fundamental para avaliar a capacidade do modelo de generalizar e reconhecer corretamente novos dados, refletindo assim sua eficácia em cenários reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4eef7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:19:56.285929Z",
     "start_time": "2024-03-06T11:19:54.667607Z"
    },
    "id": "def4eef7",
    "outputId": "077eb176-a4d0-41a1-c9cc-8bf41c74fec4"
   },
   "outputs": [],
   "source": [
    "# Avalia o modelo\n",
    "erro_teste, acc_teste = modelo_reconhecimento.evaluate(imagens_teste, labels_teste, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5884fb6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:20:09.359229Z",
     "start_time": "2024-03-06T11:20:09.354283Z"
    },
    "id": "5884fb6e"
   },
   "outputs": [],
   "source": [
    "print('\\nAcurácia com Dados de Teste:', acc_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b01dd86d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T12:24:54.259169Z",
     "start_time": "2024-03-06T12:24:54.254691Z"
    },
    "id": "b01dd86d"
   },
   "outputs": [],
   "source": [
    "# Carrega uma nova imagem\n",
    "nova_imagem = Image.open(\"dados_verificacao/nova_imagem1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e94ba112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T12:24:54.958337Z",
     "start_time": "2024-03-06T12:24:54.949483Z"
    },
    "id": "e94ba112"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1919, 1199)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensões da imagem (em pixels)\n",
    "nova_imagem.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8544e82c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T12:24:55.555090Z",
     "start_time": "2024-03-06T12:24:55.550097Z"
    },
    "id": "8544e82c"
   },
   "outputs": [],
   "source": [
    "# Obtém largura e altura da imagem\n",
    "largura = nova_imagem.width\n",
    "altura = nova_imagem.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "892ab029",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T12:24:56.129976Z",
     "start_time": "2024-03-06T12:24:56.123499Z"
    },
    "id": "892ab029"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A largura da imagem é:  1919\n",
      "A altura da imagem é:  1199\n"
     ]
    }
   ],
   "source": [
    "print(\"A largura da imagem é: \", largura)\n",
    "print(\"A altura da imagem é: \", altura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0224525b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T12:24:56.687518Z",
     "start_time": "2024-03-06T12:24:56.651604Z"
    },
    "id": "0224525b"
   },
   "outputs": [],
   "source": [
    "# Redimensiona para 32x32 pixels\n",
    "nova_imagem = nova_imagem.resize((32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ed685cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T12:25:18.773868Z",
     "start_time": "2024-03-06T12:25:18.715355Z"
    },
    "id": "7ed685cf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exibir a imagem\n",
    "plt.figure(figsize = (1,1))\n",
    "plt.imshow(nova_imagem)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897af67c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:22:58.584369Z",
     "start_time": "2024-03-06T11:22:58.581225Z"
    },
    "id": "897af67c"
   },
   "outputs": [],
   "source": [
    "# Converte a imagem para um array NumPy e normaliza\n",
    "nova_imagem_array = np.array(nova_imagem) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ebff6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:23:17.992609Z",
     "start_time": "2024-03-06T11:23:17.989249Z"
    },
    "id": "516ebff6"
   },
   "outputs": [],
   "source": [
    "# Expande a dimensão do array para que ele tenha o formato (1, 32, 32, 3)\n",
    "nova_imagem_array = np.expand_dims(nova_imagem_array, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98da1f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:23:18.631342Z",
     "start_time": "2024-03-06T11:23:18.572710Z"
    },
    "id": "98da1f69"
   },
   "outputs": [],
   "source": [
    "# Previsões\n",
    "previsoes = modelo_reconhecimento.predict(nova_imagem_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a9a5ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:23:19.181721Z",
     "start_time": "2024-03-06T11:23:19.177749Z"
    },
    "id": "b2a9a5ba"
   },
   "outputs": [],
   "source": [
    "print(previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad3dfec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:23:19.998413Z",
     "start_time": "2024-03-06T11:23:19.994292Z"
    },
    "id": "1ad3dfec"
   },
   "outputs": [],
   "source": [
    "# Obtém a classe com maior probabilidade e o nome da classe\n",
    "classe_prevista = np.argmax(previsoes)\n",
    "nome_classe_prevista = classes[classe_prevista]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e361b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:23:20.950615Z",
     "start_time": "2024-03-06T11:23:20.946640Z"
    },
    "id": "d13e361b"
   },
   "outputs": [],
   "source": [
    "print(\"A nova imagem foi classificada como:\", nome_classe_prevista)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fef5a0",
   "metadata": {
    "id": "19fef5a0"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>28.1.5 Salvado e Carregando o Modelo </strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3efc18",
   "metadata": {
    "id": "4e3efc18"
   },
   "source": [
    "É viável preservar o modelo treinado salvando-o, permitindo que seja carregado apenas quando necessário. Esta abordagem é eficaz mesmo após reiniciar o kernel e limpar todas as saídas do Jupyter Notebook. Os dados do modelo permanecem acessíveis e podem ser facilmente recuperados através do carregamento do arquivo salvo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1770f2ca",
   "metadata": {
    "id": "1770f2ca"
   },
   "source": [
    "#### Salvando o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0f51f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:24:02.643286Z",
     "start_time": "2024-03-06T11:24:02.601997Z"
    },
    "id": "f1f0f51f"
   },
   "outputs": [],
   "source": [
    "modelo_reconhecimento.save('reconhecimento_de_imagem.h5')  # Salva o modelo no formato HDF5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f268a1b",
   "metadata": {
    "id": "2f268a1b"
   },
   "source": [
    "#### Carregando o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a27e151",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:24:50.898494Z",
     "start_time": "2024-03-06T11:24:50.777974Z"
    },
    "id": "6a27e151"
   },
   "outputs": [],
   "source": [
    "modelo_reconhecimento = load_model('reconhecimento_de_imagem.h5')  # Carrega o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48cc99d",
   "metadata": {
    "id": "a48cc99d"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>28.1.6 Empacotando o Modelo </strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0267c3",
   "metadata": {
    "id": "fa0267c3"
   },
   "source": [
    "Você deve ter percebido as diversas etapas envolvidas na compilação das células até a criação do modelo. No entanto, uma vez que o modelo é treinado, podemos simplificar seu uso encapsulando as etapas necessárias em uma função dedicada. Esta abordagem facilita a reutilização do modelo para novas imagens sem a necessidade de repetir todo o processo de treinamento ou pré-processamento. A função reconhecer_imagem ilustra essa prática: ela carrega um modelo previamente treinado e uma nova imagem, executa as etapas de pré-processamento necessárias, e usa o modelo para classificar a imagem. Este método não apenas economiza tempo, mas também torna o uso do modelo para inferência em novas imagens uma tarefa muito mais direta e eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd0fa47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:25:36.456512Z",
     "start_time": "2024-03-06T11:25:36.449223Z"
    },
    "id": "afd0fa47"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def reconhecer_imagem(nome_img,arquivo):\n",
    "\n",
    "    modelo_reconhecimento = load_model(arquivo)  # Carrega o modelo\n",
    "\n",
    "    # Clases das imagens\n",
    "    classes = ['Avião', 'Automóvel', 'Pássaro', 'Gato', 'Cervo',\\\n",
    "               'Cachorro', 'Sapo', 'Cavalo', 'Barco', 'Caminhão']\n",
    "\n",
    "    # Carrega uma nova imagem\n",
    "    nova_imagem = Image.open(nome_img)\n",
    "\n",
    "    # Dimensões da imagem (em pixels)\n",
    "    nova_imagem.size\n",
    "\n",
    "    # Obtém largura e altura da imagem\n",
    "    largura = nova_imagem.width\n",
    "    altura = nova_imagem.height\n",
    "\n",
    "    # Redimensiona para 32x32 pixels\n",
    "    nova_imagem = nova_imagem.resize((32, 32))\n",
    "\n",
    "    # Exibir a imagem\n",
    "    plt.figure(figsize = (1,1))\n",
    "    plt.imshow(nova_imagem)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "    # Converte a imagem para um array NumPy e normaliza\n",
    "    nova_imagem_array = np.array(nova_imagem) / 255.0\n",
    "\n",
    "    # Expande a dimensão do array para que ele tenha o formato (1, 32, 32, 3)\n",
    "    nova_imagem_array = np.expand_dims(nova_imagem_array, axis = 0)\n",
    "\n",
    "    # Previsões\n",
    "    previsoes = modelo_reconhecimento.predict(nova_imagem_array)\n",
    "\n",
    "    # Obtém a classe com maior probabilidade e o nome da classe\n",
    "    classe_prevista = np.argmax(previsoes)\n",
    "    nome_classe_prevista = classes[classe_prevista]\n",
    "\n",
    "    print(\"A nova imagem foi classificada como:\", nome_classe_prevista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b8eab5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:26:14.231751Z",
     "start_time": "2024-03-06T11:26:13.975311Z"
    },
    "id": "e0b8eab5",
    "outputId": "cd0281e9-5619-4ddd-d804-68fb24575dc9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Chamando a função associada ao modelo treinado\n",
    "reconhecer_imagem('dados_verificacao/nova_imagem6.jpg','reconhecimento_de_imagem.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b22cb7c",
   "metadata": {
    "id": "9b22cb7c"
   },
   "source": [
    "## <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 22px;\"><strong>28.2 Exemplo Com \"Dados Próprios\"</strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b65c054",
   "metadata": {
    "id": "3b65c054"
   },
   "source": [
    "Vamos iniciar um tutorial passo a passo sobre o treinamento de uma rede neural para reconhecimento de imagens, utilizando dados personalizados do usuário. Este processo abrange diversas etapas, começando pela formatação das imagens para um tamanho padrão, seguida pela definição das classes e pela preparação dos dados para treinamento. Utilizaremos uma seleção específica de dados do dataset CIFAR-10, que, para fins didáticos, vamos considerar como se fossem dados próprios. Inicialmente, extrairemos as imagens processadas em lote (batch) para o formato PNG. Em seguida, selecionaremos imagens de apenas três categorias - Avião, Automóvel e Pássaro - e as processaremos em lote. Este tutorial é abrangente e detalhado, portanto, acompanhe as células de código a seguir para entender completamente cada etapa do processo desde o início."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d601349",
   "metadata": {
    "id": "2d601349"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>28.2.1 Visualização das Imagens de Treino no Formato PNG </strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a960f0c",
   "metadata": {
    "id": "0a960f0c"
   },
   "source": [
    "Inicialmente você deve baixar o dataset CIFAR-10. Isso pode ser feito no link: https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz. Outros formatos a serem utilizados em Matlab e C podem ser encontrados em: https://www.cs.toronto.edu/~kriz/cifar.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b2b59c",
   "metadata": {
    "id": "93b2b59c"
   },
   "source": [
    "Após baixar o arquivo extraia o seu conteúdo para a pasta \"data_batchs\". Em seguida execute as células a seguir para visualizar uma das imagens disponíveis no lote \"data_batch_1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1412d5a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:30:07.071536Z",
     "start_time": "2024-03-06T11:30:07.066627Z"
    },
    "id": "1412d5a3"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c6eb50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:30:40.837298Z",
     "start_time": "2024-03-06T11:30:40.708954Z"
    },
    "id": "d3c6eb50"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Substitua 'caminho_do_arquivo' pelo caminho do arquivo descompactado\n",
    "with open('cifar-10-batches-py/data_batch_1', 'rb') as file:\n",
    "    dict = pickle.load(file, encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba2e2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:31:26.470740Z",
     "start_time": "2024-03-06T11:31:26.335403Z"
    },
    "id": "68ba2e2a",
    "outputId": "21de015d-217c-4f22-d3de-0c8ac610aa2b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Função para converter os dados do CIFAR-10 para uma imagem RGB\n",
    "def cifar10_to_img(cifar10_data):\n",
    "    img_r = cifar10_data[:1024].reshape((32, 32))\n",
    "    img_g = cifar10_data[1024:2048].reshape((32, 32))\n",
    "    img_b = cifar10_data[2048:].reshape((32, 32))\n",
    "    img = np.dstack((img_r, img_g, img_b))\n",
    "    return img\n",
    "\n",
    "# Exemplo de como visualizar a primeira imagem\n",
    "img = cifar10_to_img(dict[b'data'][1])\n",
    "plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619027c1",
   "metadata": {
    "id": "619027c1"
   },
   "source": [
    "Como vamos fazer o processo do zero vamos desconverter as imagens em lote para o formato png para a escolha das categorias. O processo pode demorar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0431ab89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:33:22.658699Z",
     "start_time": "2024-03-06T11:32:22.505605Z"
    },
    "id": "0431ab89"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def save_images_from_pickle_with_labels(file_path, save_dir):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        # Carregando o arquivo batch\n",
    "        batch = pickle.load(file, encoding='bytes')\n",
    "        images = batch[b'data']\n",
    "        labels = batch[b'labels']\n",
    "\n",
    "        # Reshape das imagens\n",
    "        images = images.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "\n",
    "        # Loop para salvar cada imagem\n",
    "        for i, (image_array, label) in enumerate(zip(images, labels)):\n",
    "            # Criar diretório para o label, se ainda não existir\n",
    "            label_dir = os.path.join(save_dir, f'label_{label}')\n",
    "            if not os.path.exists(label_dir):\n",
    "                os.makedirs(label_dir)\n",
    "\n",
    "            # Salvar a imagem\n",
    "            image = Image.fromarray(image_array)\n",
    "            image_path = os.path.join(label_dir, f'image_{i}_label_{label}.png')\n",
    "            image.save(image_path)\n",
    "\n",
    "\n",
    "# Criando a pasta na qual as imagens serão salvas\n",
    "save_dir = 'imagens_png'  # Substitua com o caminho desejado\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "\n",
    "# Caminho da pasta onde os arquivos batch estão localizados\n",
    "batch_folder = 'cifar-10-batches-py'\n",
    "\n",
    "# Lista dos caminhos dos arquivos batch\n",
    "file_paths = [os.path.join(batch_folder, f'data_batch_{i}') for i in range(1, 6)]  # De data_batch_1 a data_batch_5\n",
    "\n",
    "# Loop para processar cada arquivo\n",
    "for file_path in file_paths:\n",
    "    save_images_from_pickle_with_labels(file_path, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb10bfc",
   "metadata": {
    "id": "ccb10bfc"
   },
   "source": [
    "Navegue até a pasta \"imagens_png\" e observe as subpastas correspondentes aos labels, \"label_0\", \"label_1\", \"label_2\", ..., \"labrl_9\" (\"Avião\", \"Automóvel\", \"Pássaro\", ..., \"Caminhão\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b284f5",
   "metadata": {
    "id": "60b284f5"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>28.2.2 Escolha das Classes do Nosso Treino </strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfbd9b2",
   "metadata": {
    "id": "3bfbd9b2"
   },
   "source": [
    "Iniciaremos agora o experimento com as imagens das categorias Avião, Automóvel e Pássaro. Começaremos a partir de suas respectivas pastas, que contêm imagens no formato PNG. Estas imagens serão convertidas em um único arquivo de lote para facilitar o processamento. Crie a pasta \"imagens_nosso_teste\" e coloque nela as pastas das imagnes correspondentes aos \"label_0\", \"label_1\" e \"label_2\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca495db2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:37:07.317792Z",
     "start_time": "2024-03-06T11:37:00.537691Z"
    },
    "id": "ca495db2"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_images_from_folder(base_folder):\n",
    "    data = []\n",
    "    labels = []\n",
    "    label_dict = {'label_0': 0, 'label_1': 1, 'label_2': 2}\n",
    "\n",
    "    for label_folder, label in label_dict.items():\n",
    "        folder_path = os.path.join(base_folder, label_folder)\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.png') or filename.endswith('.jpg') or filename.endswith('.jpeg'):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                img = Image.open(img_path)\n",
    "                img = np.array(img)\n",
    "                data.append(img)\n",
    "                labels.append(label)\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Caminho para a pasta com as imagens e rótulos\n",
    "base_folder = 'imagens_nosso_teste'\n",
    "data, labels = load_images_from_folder(base_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f59086e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:37:36.235415Z",
     "start_time": "2024-03-06T11:37:36.153357Z"
    },
    "id": "9f59086e"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def create_batch_file(data, labels, output_file):\n",
    "    batch = {\n",
    "        'data': data,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(batch, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Caminho para o arquivo batch que será criado\n",
    "output_file = 'meu_batch_personalizado'\n",
    "create_batch_file(data, labels, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3911a3",
   "metadata": {
    "id": "8b3911a3"
   },
   "source": [
    "Navegue até a pasta \"imagens_nosso_teste\" e procure o arquivo \"meu_batch_personalizado\". Este será o arquivo que utilizaremos para o treinamento do nosso modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e760e6f1",
   "metadata": {
    "id": "e760e6f1"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>28.2.3 Construindo as Classes e Definindo as Imagens de Treino</strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11407116",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:38:19.632137Z",
     "start_time": "2024-03-06T11:38:19.544623Z"
    },
    "id": "11407116"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def load_custom_data(batch_file):\n",
    "    with open(batch_file, 'rb') as file:\n",
    "        batch = pickle.load(file)\n",
    "        imagens = np.array(batch['data'])\n",
    "        labels = np.array(batch['labels'])\n",
    "    return imagens, labels\n",
    "\n",
    "# Caminho para o seu arquivo batch personalizado\n",
    "batch_file = 'meu_batch_personalizado'\n",
    "\n",
    "# Carregando os dados do seu arquivo batch\n",
    "imagens, labels = load_custom_data(batch_file)\n",
    "\n",
    "# Embaralhar os dados\n",
    "indices = np.arange(len(imagens))\n",
    "np.random.shuffle(indices)\n",
    "imagens = imagens[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "num_treino = int(len(imagens) * 0.8)  # 80% para treino, 20% para teste\n",
    "imagens_treino, imagens_teste = imagens[:num_treino], imagens[num_treino:]\n",
    "labels_treino, labels_teste = labels[:num_treino], labels[num_treino:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934595d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:38:46.355718Z",
     "start_time": "2024-03-06T11:38:46.352820Z"
    },
    "id": "934595d6"
   },
   "outputs": [],
   "source": [
    "# Clases das imagens\n",
    "classes = ['Avião', 'Automóvel', 'Pássaro']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5556c47a",
   "metadata": {
    "id": "5556c47a"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>28.2.4 Carregamento e Visualização das Imagens </strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d76450",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:39:09.923151Z",
     "start_time": "2024-03-06T11:39:09.824729Z"
    },
    "id": "64d76450"
   },
   "outputs": [],
   "source": [
    "# Normaliza os valores dos pixels para que os dados fiquem na mesma escala\n",
    "imagens_treino = imagens_treino / 255.0\n",
    "imagens_teste = imagens_teste / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966da334",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:39:12.768080Z",
     "start_time": "2024-03-06T11:39:11.744216Z"
    },
    "id": "966da334",
    "outputId": "95b88935-07ac-43cd-b51f-b062498fdebc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def visualiza_imagens_aleatorias(images, labels, classes, num_images=25):\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "    # Seleciona índices aleatórios\n",
    "    indices_aleatorios = np.random.choice(range(len(images)), num_images, replace=False)\n",
    "\n",
    "    for i, idx in enumerate(indices_aleatorios):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[idx], cmap=plt.cm.binary)\n",
    "\n",
    "        # Ajuste para rótulos 1D ou 2D\n",
    "        label = labels[idx] if labels.ndim == 1 else labels[idx][0]\n",
    "        plt.xlabel(classes[label])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Substitua 'classes' pelos nomes das suas classes\n",
    "classes = ['Avião', 'Carro', 'Ave']  # Exemplo\n",
    "visualiza_imagens_aleatorias(imagens_treino, labels_treino, classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a5f120",
   "metadata": {
    "id": "12a5f120"
   },
   "source": [
    "#### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 14px;\"><strong>28.2.4.1 Testando a Randomização</strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5a838e",
   "metadata": {
    "id": "ae5a838e"
   },
   "source": [
    "Após converter as imagens em formato PNG para o nosso arquivo em lote, decidimos embaralhar aleatoriamente as imagens. Este passo é crucial para evitar qualquer viés durante o treinamento da rede neural. Em um conjunto de dados não randomizado, se as imagens estivessem agrupadas por classes, a rede poderia desenvolver um padrão de aprendizado enviesado, baseando-se na ordem das imagens em vez de suas características individuais. Para verificar a eficácia da randomização, altere o valor da variável \"índice\" de zero para 1, 2, 3, etc., e observe que as imagens agora aparecem em uma ordem não sequencial, sem uma organização específica por classes. Esta abordagem assegura que o modelo aprenda a identificar características relevantes para cada classe, independentemente da sequência em que as imagens são apresentadas durante o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b13a3fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:39:53.969006Z",
     "start_time": "2024-03-06T11:39:53.713690Z"
    },
    "id": "3b13a3fc",
    "outputId": "e54723a6-1c7c-47e1-b8b3-d97b091f6f83"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  # Necessário para np.argmax se labels estiverem em one-hot\n",
    "\n",
    "def visualizar_imagem_especifica(imagens, labels, indice, classes):\n",
    "    plt.figure()\n",
    "    plt.imshow(imagens[indice])\n",
    "    plt.colorbar()\n",
    "    plt.grid(False)\n",
    "    # Usa np.argmax para encontrar o índice do label se estiver em one-hot\n",
    "    label_index = np.argmax(labels[indice])\n",
    "    plt.title(f\"Label: {classes[label_index]}\")\n",
    "    plt.show()\n",
    "\n",
    "# Exemplo de uso da função\n",
    "indice = 0  # Substitua pelo índice da imagem que você quer visualizar\n",
    "classes = ['Avião', 'Automóvel', 'Pássaro']  # Substitua pelos nomes reais das suas classes\n",
    "# Supõe-se que imagens_treino e labels_treino sejam definidos anteriormente\n",
    "visualizar_imagem_especifica(imagens_treino, labels_treino, indice, classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaf02e3",
   "metadata": {
    "id": "4eaf02e3"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>28.2.5 Treinando a Rede Neural </strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ffa090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:40:36.174033Z",
     "start_time": "2024-03-06T11:40:36.120767Z"
    },
    "id": "c4ffa090"
   },
   "outputs": [],
   "source": [
    "# Modelo\n",
    "\n",
    "# Cria o objeto de sequência de camadas\n",
    "nosso_modelo = models.Sequential()\n",
    "\n",
    "# Adiciona o primeiro bloco de convolução e max pooling (camada de entrada)\n",
    "nosso_modelo.add(layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (32, 32, 3)))\n",
    "nosso_modelo.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Adiciona o segundo bloco de convolução e max pooling (camada intermediária)\n",
    "nosso_modelo.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "nosso_modelo.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Adiciona o terceiro bloco de convolução e max pooling (camada intermediária)\n",
    "nosso_modelo.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "nosso_modelo.add(layers.MaxPooling2D((2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc6078",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:40:42.847237Z",
     "start_time": "2024-03-06T11:40:42.816539Z"
    },
    "id": "5bdc6078"
   },
   "outputs": [],
   "source": [
    "# Adicionar camadas de classificação\n",
    "nosso_modelo.add(layers.Flatten())\n",
    "nosso_modelo.add(layers.Dense(64, activation = 'relu'))\n",
    "nosso_modelo.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae664a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:40:45.450340Z",
     "start_time": "2024-03-06T11:40:45.424278Z"
    },
    "id": "08ae664a",
    "outputId": "8c34782d-32f8-43e5-9653-e537c8ae224d"
   },
   "outputs": [],
   "source": [
    "# Sumário do modelo\n",
    "nosso_modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f36ec9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:40:52.946804Z",
     "start_time": "2024-03-06T11:40:52.936561Z"
    },
    "id": "d1f36ec9"
   },
   "outputs": [],
   "source": [
    "# Compilação do modelo\n",
    "nosso_modelo.compile(optimizer = 'adam',\n",
    "                   loss = 'sparse_categorical_crossentropy',\n",
    "                   metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a825b8cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:41:49.475564Z",
     "start_time": "2024-03-06T11:40:54.495969Z"
    },
    "id": "a825b8cc",
    "outputId": "29dc681d-9271-4802-fde9-a1152ecdd9a5"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = nosso_modelo.fit(imagens_treino,\n",
    "                         labels_treino,\n",
    "                         epochs = 10,\n",
    "                         validation_data = (imagens_teste, labels_teste))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4590bc2",
   "metadata": {
    "id": "a4590bc2"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>28.2.6 Avaliando o Treinamento </strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b70cdd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:42:02.452600Z",
     "start_time": "2024-03-06T11:42:01.991145Z"
    },
    "id": "7b70cdd1",
    "outputId": "e865ace3-1c3d-4e13-cf5a-1a8ebfe9d37d"
   },
   "outputs": [],
   "source": [
    "# Avalia o modelo\n",
    "erro_teste, acc_teste = nosso_modelo.evaluate(imagens_teste, labels_teste, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f77f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:42:02.581323Z",
     "start_time": "2024-03-06T11:42:02.577265Z"
    },
    "id": "118f77f1",
    "outputId": "c0ddc52c-5a93-4eca-df9f-a523f99651ef"
   },
   "outputs": [],
   "source": [
    "print('\\nAcurácia com Dados de Teste:', acc_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e2033",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:44:01.548884Z",
     "start_time": "2024-03-06T11:44:01.542890Z"
    },
    "id": "940e2033"
   },
   "outputs": [],
   "source": [
    "# Carrega uma nova imagem\n",
    "nova_imagem = Image.open(\"dados_verificacao_nosso_modelo/nosso_modelo_img_4.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb70bc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:44:01.883570Z",
     "start_time": "2024-03-06T11:44:01.879663Z"
    },
    "id": "aeb70bc3",
    "outputId": "23ab9edc-b804-4c3a-d091-35773a2871c9"
   },
   "outputs": [],
   "source": [
    "# Dimensões da imagem (em pixels)\n",
    "nova_imagem.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83526f63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:44:02.075039Z",
     "start_time": "2024-03-06T11:44:02.071654Z"
    },
    "id": "83526f63"
   },
   "outputs": [],
   "source": [
    "# Obtém largura e altura da imagem\n",
    "largura = nova_imagem.width\n",
    "altura = nova_imagem.height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0709d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:44:02.339120Z",
     "start_time": "2024-03-06T11:44:02.334909Z"
    },
    "id": "8a0709d4",
    "outputId": "3b9f6656-5c1b-4ec1-9d37-5803dbb22e93"
   },
   "outputs": [],
   "source": [
    "print(\"A largura da imagem é: \", largura)\n",
    "print(\"A altura da imagem é: \", altura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd1c40f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:44:02.579020Z",
     "start_time": "2024-03-06T11:44:02.569014Z"
    },
    "id": "3dd1c40f"
   },
   "outputs": [],
   "source": [
    "# Redimensiona para 32x32 pixels\n",
    "nova_imagem = nova_imagem.resize((32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f56f065",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:44:02.809457Z",
     "start_time": "2024-03-06T11:44:02.766916Z"
    },
    "id": "0f56f065",
    "outputId": "b83bc39e-f9c8-4105-fd94-960fef6a4a86"
   },
   "outputs": [],
   "source": [
    "# Exibir a imagem\n",
    "plt.figure(figsize = (1,1))\n",
    "plt.imshow(nova_imagem)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c310f5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:44:03.234797Z",
     "start_time": "2024-03-06T11:44:03.231740Z"
    },
    "id": "4c310f5d"
   },
   "outputs": [],
   "source": [
    "# Converte a imagem para um array NumPy e normaliza\n",
    "nova_imagem_array = np.array(nova_imagem) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f23261a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:44:03.532712Z",
     "start_time": "2024-03-06T11:44:03.528434Z"
    },
    "id": "8f23261a"
   },
   "outputs": [],
   "source": [
    "# Expande a dimensão do array para que ele tenha o formato (1, 32, 32, 3)\n",
    "nova_imagem_array = np.expand_dims(nova_imagem_array, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9744c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:44:05.274030Z",
     "start_time": "2024-03-06T11:44:05.215482Z"
    },
    "id": "cc9744c3",
    "outputId": "75effa95-0f5c-46cd-86f5-3d08393469e6"
   },
   "outputs": [],
   "source": [
    "# Previsões\n",
    "previsoes = nosso_modelo.predict(nova_imagem_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d612de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:44:05.983308Z",
     "start_time": "2024-03-06T11:44:05.978902Z"
    },
    "id": "63d612de",
    "outputId": "db0e5c43-0da3-45c3-aed5-682472ab0cf8"
   },
   "outputs": [],
   "source": [
    "print(previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eae93b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:44:06.309000Z",
     "start_time": "2024-03-06T11:44:06.305363Z"
    },
    "id": "6eae93b3"
   },
   "outputs": [],
   "source": [
    "# Obtém a classe com maior probabilidade e o nome da classe\n",
    "classe_prevista = np.argmax(previsoes)\n",
    "nome_classe_prevista = classes[classe_prevista]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef10adaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:44:07.534066Z",
     "start_time": "2024-03-06T11:44:07.529664Z"
    },
    "id": "ef10adaf",
    "outputId": "803826b0-9788-4431-c7c9-36f786368554"
   },
   "outputs": [],
   "source": [
    "print(\"A nova imagem foi classificada como:\", nome_classe_prevista)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c5eb3a",
   "metadata": {
    "id": "e0c5eb3a"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>28.2.7 Salvado e Carregando o Modelo </strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c64eca2",
   "metadata": {
    "id": "6c64eca2"
   },
   "source": [
    "É viável preservar o modelo treinado salvando-o, permitindo que seja carregado apenas quando necessário. Esta abordagem é eficaz mesmo após reiniciar o kernel e limpar todas as saídas do Jupyter Notebook. Os dados do modelo permanecem acessíveis e podem ser facilmente recuperados através do carregamento do arquivo salvo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86265763",
   "metadata": {
    "id": "86265763"
   },
   "source": [
    "#### Salvando o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fcce5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:44:35.771754Z",
     "start_time": "2024-03-06T11:44:35.743776Z"
    },
    "id": "d0fcce5f"
   },
   "outputs": [],
   "source": [
    "nosso_modelo.save('nosso_modelo_de_reconhecimento.h5')  # Salva o modelo no formato HDF5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6867593f",
   "metadata": {
    "id": "6867593f"
   },
   "source": [
    "#### Carregando o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe532660",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:44:52.023882Z",
     "start_time": "2024-03-06T11:44:51.911329Z"
    },
    "id": "fe532660"
   },
   "outputs": [],
   "source": [
    "modelo_reconhecimento = load_model('nosso_modelo_de_reconhecimento.h5')  # Carrega o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc9d47d",
   "metadata": {
    "id": "3fc9d47d"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>28.2.8 Empacotando o Modelo </strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb409dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:46:35.942273Z",
     "start_time": "2024-03-06T11:46:28.200198Z"
    },
    "id": "7fb409dc"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def reconhecer_imagem(nome_img, arquivo_modelo):\n",
    "\n",
    "    # Carrega o modelo treinado\n",
    "    modelo_reconhecimento = load_model(arquivo_modelo)\n",
    "\n",
    "    # Classes das imagens (conforme seus labels personalizados)\n",
    "    classes = ['Avião', 'Automóvel', 'Pássaro']\n",
    "\n",
    "    # Carrega uma nova imagem\n",
    "    nova_imagem = Image.open(nome_img)\n",
    "\n",
    "    # Redimensiona para 32x32 pixels (conforme o esperado pelo modelo)\n",
    "    nova_imagem = nova_imagem.resize((32, 32))\n",
    "\n",
    "    # Exibir a imagem\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    plt.imshow(nova_imagem)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "    # Converte a imagem para um array NumPy e normaliza\n",
    "    nova_imagem_array = np.array(nova_imagem) / 255.0\n",
    "\n",
    "    # Expande a dimensão do array para o formato esperado pelo modelo\n",
    "    nova_imagem_array = np.expand_dims(nova_imagem_array, axis=0)\n",
    "\n",
    "    # Previsões\n",
    "    previsoes = modelo_reconhecimento.predict(nova_imagem_array)\n",
    "\n",
    "    # Obtém a classe com maior probabilidade e o nome da classe\n",
    "    classe_prevista = np.argmax(previsoes)\n",
    "    nome_classe_prevista = classes[classe_prevista]\n",
    "\n",
    "    print(\"A nova imagem foi classificada como:\", nome_classe_prevista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a82b43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T11:47:05.071801Z",
     "start_time": "2024-03-06T11:47:04.813800Z"
    },
    "id": "96a82b43",
    "outputId": "ffd3b420-f5e1-4db2-c6a0-b32d10c80536",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reconhecer_imagem('dados_verificacao_nosso_modelo/nosso_modelo_img_2.jpg','nosso_modelo_de_reconhecimento.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc64daf",
   "metadata": {
    "id": "8fc64daf"
   },
   "source": [
    "## <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 22px;\"><strong>28.3 Conversão de Imagem Para Tamanho 32x32</strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e266c9",
   "metadata": {
    "id": "b0e266c9"
   },
   "source": [
    "O banco de dados usando para nosso treinamento já se apresentava em imagens com tamanho 32x32 pixels. Contudo, em muitas situações coletaremos imagens em diversos tamanhos. Apresentaremos a seguir métodos para a conversão para o tamanho 32x32 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71df883",
   "metadata": {
    "id": "b71df883"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>28.3.1 Redimensionamento com Manutenção da Relação de Aspecto</strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce2fd96",
   "metadata": {
    "id": "cce2fd96"
   },
   "source": [
    "Primeiramente, redimensione a imagem para que o maior lado (largura ou altura) seja igual a 32 pixels, mantendo a relação de aspecto. Em seguida, preencha o espaço restante para formar uma imagem 32x32. Este método é útil em situações onde é importante manter a integridade visual da imagem original, sem distorcer sua proporção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea918ae2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T12:21:13.683334Z",
     "start_time": "2024-03-06T12:21:13.586564Z"
    },
    "id": "ea918ae2"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def resize_and_pad_images(source_folder, target_folder, size=(32, 32), fill_color=(0, 0, 0)):\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "\n",
    "    for filename in os.listdir(source_folder):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(source_folder, filename)\n",
    "            img = Image.open(img_path)\n",
    "\n",
    "            # Redimensionamento mantendo a relação de aspecto\n",
    "            img.thumbnail((size[0], size[1]))\n",
    "\n",
    "            # Criando uma nova imagem com fundo preto\n",
    "            new_img = Image.new(\"RGB\", size, fill_color)\n",
    "\n",
    "            # Calculando posição para colar a imagem redimensionada\n",
    "            x = (size[0] - img.size[0]) // 2\n",
    "            y = (size[1] - img.size[1]) // 2\n",
    "\n",
    "            new_img.paste(img, (x, y))\n",
    "            new_img.save(os.path.join(target_folder, filename))\n",
    "\n",
    "source_folder = 'imagens_originais'\n",
    "target_folder = 'imagens_processadas_aspect_ratio'\n",
    "resize_and_pad_images(source_folder, target_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51725a2f",
   "metadata": {
    "id": "51725a2f"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>28.3.2 Preenchimento (Padding)</strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1afcbc2",
   "metadata": {
    "id": "e1afcbc2"
   },
   "source": [
    "Redimensione a imagem para caber dentro de um quadrado 32x32, mantendo a relação de aspecto, e preencha o espaço restante com um fundo (como preto, branco ou algum valor de pixel neutro). O uso deste método é semelhante ao anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adc57c5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T12:22:18.261136Z",
     "start_time": "2024-03-06T12:22:18.106640Z"
    },
    "id": "adc57c5d"
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "\n",
    "def resize_and_pad_images(source_folder, target_folder, size=(32, 32), fill_color=(0, 0, 0)):\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "\n",
    "    for filename in os.listdir(source_folder):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(source_folder, filename)\n",
    "            img = Image.open(img_path)\n",
    "\n",
    "            # Mantendo a relação de aspecto\n",
    "            ratio = min(size[0] / img.size[0], size[1] / img.size[1])\n",
    "            new_size = int(img.size[0] * ratio), int(img.size[1] * ratio)\n",
    "            img = img.resize(new_size, Image.Resampling.LANCZOS)  # Usando LANCZOS para redimensionamento\n",
    "\n",
    "            # Criando uma nova imagem com fundo preto\n",
    "            new_img = Image.new(\"RGB\", size, fill_color)\n",
    "\n",
    "            # Calculando posição para colar a imagem redimensionada\n",
    "            x = (size[0] - new_size[0]) // 2\n",
    "            y = (size[1] - new_size[1]) // 2\n",
    "\n",
    "            new_img.paste(img, (x, y))\n",
    "            new_img.save(os.path.join(target_folder, filename))\n",
    "\n",
    "source_folder = 'imagens_originais'\n",
    "target_folder = 'imagens_processadas_padding'\n",
    "resize_and_pad_images(source_folder, target_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a15192",
   "metadata": {
    "id": "b8a15192"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>28.3.3 Recorte Central (Cropping)</strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7a06c6",
   "metadata": {
    "id": "fb7a06c6"
   },
   "source": [
    "Redimensione a imagem para que o menor lado seja de 32 pixels, mantendo a relação de aspecto, e então faça um recorte central para obter uma imagem quadrada de 32x32. Este método é ideal para situações onde é necessário padronizar o tamanho das imagens sem distorcer a relação de aspecto e mantendo o foco central da imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d8041db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T12:23:38.368896Z",
     "start_time": "2024-03-06T12:23:38.210838Z"
    },
    "id": "0d8041db"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def resize_and_crop_images(source_folder, target_folder, size=(32, 32)):\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "\n",
    "    for filename in os.listdir(source_folder):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(source_folder, filename)\n",
    "            img = Image.open(img_path)\n",
    "\n",
    "            # Calculando a nova dimensão mantendo a relação de aspecto\n",
    "            ratio = max(size[0] / img.size[0], size[1] / img.size[1])\n",
    "            new_size = int(img.size[0] * ratio), int(img.size[1] * ratio)\n",
    "            img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "            # Calculando área para o recorte central\n",
    "            left = (img.width - size[0]) / 2\n",
    "            top = (img.height - size[1]) / 2\n",
    "            right = (img.width + size[0]) / 2\n",
    "            bottom = (img.height + size[1]) / 2\n",
    "\n",
    "            img = img.crop((left, top, right, bottom))\n",
    "            img.save(os.path.join(target_folder, filename))\n",
    "\n",
    "source_folder = 'imagens_originais'\n",
    "target_folder = 'imagens_processadas_cropping'\n",
    "resize_and_crop_images(source_folder, target_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ec8ba",
   "metadata": {
    "heading_collapsed": true,
    "id": "c59ec8ba"
   },
   "source": [
    "## <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 22px;\"><strong> Extras (em construção)</strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987a871e",
   "metadata": {
    "hidden": true,
    "id": "987a871e"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>1. Exemplo de Convolução de Uma Imagem</strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cb5dda",
   "metadata": {
    "hidden": true,
    "id": "08cb5dda"
   },
   "source": [
    "O código a seguir apresenta as etapas envolvidas no processo de convolução de uma imagem usando uma Rede Neural Convolucional (CNN) com a biblioteca TensorFlow e Keras.\n",
    "\n",
    "1. **Carregamento e Preparação da Imagem**: Os códigos começam carregando uma imagem e preparando-a para processamento, incluindo redimensionamento e normalização. Isso é fundamental para garantir que a imagem esteja no formato correto para ser processada pela CNN.\n",
    "\n",
    "2. **Construção do Modelo de CNN**: Ambos os códigos demonstram como construir uma CNN simples usando o TensorFlow e Keras. Eles definem camadas de convolução e pooling, que são componentes essenciais de uma CNN.\n",
    "\n",
    "3. **Aplicação do Modelo à Imagem**: Os códigos aplicam o modelo de CNN à imagem processada e obtêm os resultados da convolução e pooling.\n",
    "\n",
    "4. **Visualização dos Resultados**: Após aplicar o modelo, os códigos visualizam a imagem original e os mapas de características resultantes das camadas de convolução e pooling. Isso é importante para entender como a CNN transforma a imagem e quais características ela extrai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d93c17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-24T21:39:35.215089Z",
     "start_time": "2023-11-24T21:39:33.667627Z"
    },
    "hidden": true,
    "id": "07d93c17"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# Substitua 'path_to_image' pelo caminho real da sua imagem\n",
    "img_path = 'dados/nova_imagem1.jpg'  # Exemplo: 'image.jpg'\n",
    "img = load_img(img_path, target_size=(200, 200))  # Carregar a imagem e redimensionar para 200x200\n",
    "img_array = img_to_array(img)  # Converter a imagem para um array\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Adicionar uma dimensão de lote (batch)\n",
    "img_array /= 255.0  # Normalizar a imagem para o intervalo [0, 1]\n",
    "\n",
    "# Mostrando a imagem original\n",
    "plt.imshow(img)\n",
    "plt.title('Imagem Original')\n",
    "plt.axis('off')  # Ocultar os eixos\n",
    "plt.show()\n",
    "\n",
    "# Definindo a arquitetura da CNN\n",
    "input_img = Input(shape=(200, 200, 3))  # Definir o tamanho de entrada esperado\n",
    "\n",
    "# Primeira camada de convolução e pooling\n",
    "conv1 = Conv2D(4, (5, 5), activation='relu', padding='same')(input_img)\n",
    "pool1 = MaxPooling2D((2, 2), padding='same')(conv1)\n",
    "\n",
    "# Segunda camada de convolução e pooling\n",
    "conv2 = Conv2D(5, (3, 3), activation='relu', padding='same')(pool1)\n",
    "pool2 = MaxPooling2D((2, 2), padding='same')(conv2)\n",
    "\n",
    "# Criando o modelo\n",
    "model = Model(inputs=input_img, outputs=[conv1, pool1, conv2, pool2])\n",
    "model.summary()  # Visualizar a estrutura do modelo\n",
    "\n",
    "# Aplicando o modelo à imagem de entrada para obter os mapas de características intermediários\n",
    "feature_maps = model.predict(img_array)\n",
    "\n",
    "# Visualizando e plotando os mapas de características após a primeira camada de convolução\n",
    "feature_maps_conv1 = feature_maps[0]  # Mapas de características da primeira camada de convolução\n",
    "plt.figure(figsize=(20, 16))\n",
    "for i in range(feature_maps_conv1.shape[-1]):  # O número de filtros na primeira camada convolucional\n",
    "    plt.subplot(1, feature_maps_conv1.shape[-1], i+1)\n",
    "    plt.imshow(feature_maps_conv1[0, :, :, i], cmap='gray')\n",
    "    plt.title(f'Feature Map - Conv1 - Filter {i+1}')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Visualizando e plotando os mapas de características após a primeira camada de pooling\n",
    "feature_maps_pool1 = feature_maps[1]  # Mapas de características após a primeira camada de pooling\n",
    "plt.figure(figsize=(20, 16))\n",
    "for i in range(feature_maps_pool1.shape[-1]):  # O número de filtros na primeira camada convolucional\n",
    "    plt.subplot(1, feature_maps_pool1.shape[-1], i+1)\n",
    "    plt.imshow(feature_maps_pool1[0, :, :, i], cmap='gray')\n",
    "    plt.title(f'Feature Map - Pool1 - Filter {i+1}')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Visualizando e plotando os mapas de características após a segunda camada de convolução\n",
    "feature_maps_conv2 = feature_maps[2]  # Mapas de características da segunda camada de convolução\n",
    "plt.figure(figsize=(20, 16))\n",
    "for i in range(feature_maps_conv2.shape[-1]):  # O número de filtros na segunda camada convolucional\n",
    "    plt.subplot(1, feature_maps_conv2.shape[-1], i+1)\n",
    "    plt.imshow(feature_maps_conv2[0, :, :, i], cmap='gray')\n",
    "    plt.title(f'Feature Map - Conv2 - Filter {i+1}')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Visualizando e plotando os mapas de características após a segunda camada de pooling\n",
    "feature_maps_pool2 = feature_maps[3]  # Mapas de características após a segunda camada de pooling\n",
    "plt.figure(figsize=(20, 16))\n",
    "for i in range(feature_maps_pool2.shape[-1]):  # O número de filtros na segunda camada convolucional\n",
    "    plt.subplot(1, feature_maps_pool2.shape[-1], i+1)\n",
    "    plt.imshow(feature_maps_pool2[0, :, :, i], cmap='gray')\n",
    "    plt.title(f'Feature Map - Pool2 - Filter {i+1}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae4743f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T12:26:54.756799Z",
     "start_time": "2023-11-25T12:26:54.750849Z"
    },
    "hidden": true,
    "id": "8ae4743f"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>2. Filtros</strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf4eb40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T12:29:11.386265Z",
     "start_time": "2023-11-25T12:29:11.375133Z"
    },
    "hidden": true,
    "id": "acf4eb40"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "# Cria uma matriz 8x8\n",
    "matriz = np.random.rand(8, 8)\n",
    "\n",
    "# Define diferentes kernels (filtros de convolução)\n",
    "kernel_1 = np.array([[1, 0, -1],\n",
    "                     [1, 0, -1],\n",
    "                     [1, 0, -1]])  # Exemplo de kernel de detecção de borda\n",
    "kernel_2 = np.array([[0, 1, 0],\n",
    "                     [1, -4, 1],\n",
    "                     [0, 1, 0]])    # Outro exemplo de kernel\n",
    "kernels = [kernel_1, kernel_2]\n",
    "\n",
    "# Função para aplicar convolução\n",
    "def aplicar_convolucao(matriz, kernel):\n",
    "    return convolve2d(matriz, kernel, mode='same')\n",
    "\n",
    "# Define o número de convoluções\n",
    "num_convolucoes = 10\n",
    "\n",
    "# Aplica as convoluções\n",
    "for i in range(num_convolucoes):\n",
    "    kernel = kernels[i % 2]  # Alterna entre os dois kernels\n",
    "    matriz = aplicar_convolucao(matriz, kernel)\n",
    "    print(f\"Após a convolução {i + 1} com o kernel {i % 2 + 1}:\\n\", matriz, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6a3b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T12:36:31.908172Z",
     "start_time": "2023-11-25T12:36:30.568145Z"
    },
    "hidden": true,
    "id": "84c6a3b9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carrega a imagem real\n",
    "caminho_da_imagem = 'dados_verificacao/nova_imagem3.jpg'  # Substitua pelo caminho da sua imagem\n",
    "imagem = Image.open(caminho_da_imagem).convert('L')  # Convertendo para escala de cinza\n",
    "matriz = np.array(imagem)  # Convertendo a imagem para uma matriz NumPy\n",
    "\n",
    "# Define os kernels\n",
    "kernel_1 = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]])  # Exemplo de kernel de detecção de borda\n",
    "kernel_2 = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]])    # Outro exemplo de kernel\n",
    "kernels = [kernel_1, kernel_2]\n",
    "\n",
    "# Função para aplicar convolução\n",
    "def aplicar_convolucao(matriz, kernel):\n",
    "    return convolve2d(matriz, kernel, mode='same')\n",
    "\n",
    "# Número de convoluções\n",
    "num_convolucoes = 10\n",
    "\n",
    "# Aplicando as convoluções e exibindo os resultados\n",
    "for i in range(num_convolucoes):\n",
    "    kernel = kernels[i % 2]  # Alterna entre os dois kernels\n",
    "    matriz = aplicar_convolucao(matriz, kernel)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(matriz, cmap='gray')\n",
    "    plt.title(f\"Após a convolução {i + 1} com o kernel {i % 2 + 1}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e55f99",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "67e55f99"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>3. Reconhecimento e Webcam (Falta Organizar)</strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3ffbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T16:46:10.668852Z",
     "start_time": "2023-11-25T16:45:50.079050Z"
    },
    "hidden": true,
    "id": "16d3ffbf"
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5edde6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:46:04.766864Z",
     "start_time": "2023-11-25T17:45:30.233462Z"
    },
    "hidden": true,
    "id": "ee5edde6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "\n",
    "def reconhecer_imagem(img_array, modelo):\n",
    "    # Redimensiona para 32x32 pixels\n",
    "    img_array = cv2.resize(img_array, (32, 32))\n",
    "\n",
    "    # Converte a imagem para um array NumPy e normaliza\n",
    "    img_array = img_array / 255.0\n",
    "\n",
    "    # Expande a dimensão do array para o formato (1, 32, 32, 3)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Previsões\n",
    "    previsoes = modelo.predict(img_array)\n",
    "\n",
    "    # Obtém a classe com maior probabilidade\n",
    "    classe_prevista = np.argmax(previsoes)\n",
    "    return classe_prevista\n",
    "\n",
    "# Carrega o modelo\n",
    "modelo_reconhecimento = load_model('reconhecimento_de_imagem.h5')  # Substitua pelo nome do seu arquivo de modelo\n",
    "\n",
    "# Classes das imagens\n",
    "classes = ['Avião', 'Automóvel', 'Pássaro', 'Gato', 'Cervo', 'Cachorro', 'Sapo', 'Cavalo', 'Barco', 'Caminhão']\n",
    "\n",
    "# Inicializa a webcam\n",
    "cap = cv2.VideoCapture(3)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Captura frame-a-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret:\n",
    "            # Processa a imagem e faz a previsão\n",
    "            classe_prevista = reconhecer_imagem(frame, modelo_reconhecimento)\n",
    "            print(\"A nova imagem foi classificada como:\", classes[classe_prevista])\n",
    "\n",
    "            # Mostra o frame capturado\n",
    "            cv2.imshow('Frame', frame)\n",
    "\n",
    "            # Aguarda um segundo antes da próxima captura\n",
    "            time.sleep(1)\n",
    "\n",
    "        # Fecha a janela se a tecla 'q' for pressionada\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrompido pelo usuário\")\n",
    "\n",
    "# Libera a câmera e fecha todas as janelas abertas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e388df9",
   "metadata": {
    "hidden": true,
    "id": "8e388df9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379f4abd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:08:56.791669Z",
     "start_time": "2023-11-25T17:08:49.925042Z"
    },
    "hidden": true,
    "id": "379f4abd"
   },
   "outputs": [],
   "source": [
    "!pip install pywin32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6675c6b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T18:01:25.735232Z",
     "start_time": "2023-11-25T18:01:25.586130Z"
    },
    "hidden": true,
    "id": "6675c6b9"
   },
   "outputs": [],
   "source": [
    "import win32com.client\n",
    "\n",
    "def listar_dispositivos_camera_windows():\n",
    "    wmi = win32com.client.GetObject(\"winmgmts:\")\n",
    "    for item in wmi.InstancesOf(\"Win32_PnPEntity\"):\n",
    "        if item.Name and (\"camera\" in item.Name.lower() or \"webcam\" in item.Name.lower()):\n",
    "            print(item.Name)\n",
    "\n",
    "listar_dispositivos_camera_windows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb9eca4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:33:47.467680Z",
     "start_time": "2023-11-25T17:32:37.519169Z"
    },
    "hidden": true,
    "id": "7fb9eca4"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Tente diferentes índices se necessário\n",
    "indices = [0, 1, 2, 3, 4]\n",
    "\n",
    "for indice in indices:\n",
    "    cap = cv2.VideoCapture(indice)\n",
    "    if cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            cv2.imshow(f'Camera Index {indice}', frame)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f14c4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T17:34:51.348208Z",
     "start_time": "2023-11-25T17:34:33.057745Z"
    },
    "hidden": true,
    "id": "09f14c4f"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def listar_câmeras(disponiveis=10):\n",
    "    indice = 0\n",
    "    while indice < disponiveis:\n",
    "        cap = cv2.VideoCapture(indice)\n",
    "        if cap is None or not cap.isOpened():\n",
    "            print(f\"Câmera com índice {indice} não está disponível.\")\n",
    "        else:\n",
    "            print(f\"Câmera encontrada no índice {indice}.\")\n",
    "            cap.release()\n",
    "        indice += 1\n",
    "\n",
    "listar_câmeras()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5ff427",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T20:32:53.196763Z",
     "start_time": "2023-11-25T20:32:47.883490Z"
    },
    "hidden": true,
    "id": "ee5ff427"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Inicializa a webcam\n",
    "cap = cv2.VideoCapture(3)\n",
    "\n",
    "# Captura um único frame\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Verifica se a captura foi bem-sucedida\n",
    "if ret:\n",
    "    # Mostra o frame capturado\n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    # Salva a imagem no disco\n",
    "    cv2.imwrite('captura_webcam.jpg', frame)\n",
    "    print(\"Imagem salva como 'captura_webcam.jpg'\")\n",
    "\n",
    "    # Aguarda até que alguma tecla seja pressionada\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "# Libera a câmera e fecha todas as janelas abertas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6430ee87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T18:05:29.316457Z",
     "start_time": "2023-11-25T18:05:08.540073Z"
    },
    "hidden": true,
    "id": "6430ee87"
   },
   "outputs": [],
   "source": [
    "!pip install pillow mss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75b5750",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T18:05:35.120653Z",
     "start_time": "2023-11-25T18:05:31.462407Z"
    },
    "hidden": true,
    "id": "a75b5750"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import mss\n",
    "import mss.tools\n",
    "\n",
    "with mss.mss() as sct:\n",
    "    # Captura a tela\n",
    "    monitor = sct.monitors[1]  # Seleciona o primeiro monitor\n",
    "    screenshot = sct.grab(monitor)\n",
    "\n",
    "    # Salva a captura de tela\n",
    "    path = 'captura_tela.png'\n",
    "    mss.tools.to_png(screenshot.rgb, screenshot.size, output=path)\n",
    "    print(f\"Captura de tela salva como '{path}'\")\n",
    "\n",
    "    # Carrega e exibe a captura de tela\n",
    "    img = Image.open(path)\n",
    "    img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7518b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T18:13:36.240746Z",
     "start_time": "2023-11-25T18:13:29.451656Z"
    },
    "hidden": true,
    "id": "1dd7518b"
   },
   "outputs": [],
   "source": [
    "!pip install mss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced29df4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T20:15:30.352705Z",
     "start_time": "2023-11-25T20:13:59.245470Z"
    },
    "hidden": true,
    "id": "ced29df4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mss\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def reconhecer_imagem(img_array, modelo):\n",
    "    # Remove o canal alfa se a imagem tiver 4 canais\n",
    "    if img_array.shape[-1] == 4:\n",
    "        img_array = img_array[..., :3]\n",
    "\n",
    "    # Redimensiona para 32x32 pixels\n",
    "    img_array = cv2.resize(img_array, (32, 32))\n",
    "\n",
    "    # Converte a imagem para um array NumPy e normaliza\n",
    "    img_array = img_array / 255.0\n",
    "\n",
    "    # Expande a dimensão do array para o formato (1, 32, 32, 3)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Previsões\n",
    "    previsoes = modelo.predict(img_array)\n",
    "\n",
    "    # Obtém a classe com maior probabilidade\n",
    "    classe_prevista = np.argmax(previsoes)\n",
    "    return classe_prevista\n",
    "\n",
    "# Carrega o modelo\n",
    "modelo_reconhecimento = load_model('reconhecimento_de_imagem.h5')  # Substitua pelo nome do seu arquivo de modelo\n",
    "\n",
    "# Classes das imagens\n",
    "classes = ['Avião', 'Automóvel', 'Pássaro', 'Gato', 'Cervo', 'Cachorro', 'Sapo', 'Cavalo', 'Barco', 'Caminhão']\n",
    "\n",
    "# Inicializa o mss para captura de tela\n",
    "sct = mss.mss()\n",
    "\n",
    "while True:\n",
    "    # Captura a tela\n",
    "    monitor = sct.monitors[1]  # Captura o primeiro monitor\n",
    "    frame = np.array(sct.grab(monitor))\n",
    "\n",
    "    # Processa a imagem e faz a previsão\n",
    "    classe_prevista = reconhecer_imagem(frame, modelo_reconhecimento)\n",
    "    print(\"A nova imagem foi classificada como:\", classes[classe_prevista])\n",
    "\n",
    "    # Para interromper o loop, pressione Ctrl+C no terminal\n",
    "    try:\n",
    "        cv2.waitKey(10000)  # Aguarda 100 milissegundos\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "\n",
    "# Fecha todas as janelas abertas\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfac427",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T20:19:00.224969Z",
     "start_time": "2023-11-25T20:19:00.219723Z"
    },
    "heading_collapsed": true,
    "hidden": true,
    "id": "2dfac427"
   },
   "source": [
    "### <div style=\"margin-top: -20px;\">\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "\n",
    "<font color='blue'><span style=\"font-size: 18px;\"><strong>28.1.7 Reconhecimento de Imagem A Partir da Webcam (em construção)</strong></span></font>\n",
    "\n",
    "<hr style=\"border: 2px solid blue;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3973c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:51:48.084314Z",
     "start_time": "2024-03-04T13:51:48.081145Z"
    },
    "hidden": true
   },
   "source": [
    "#### Encontre o endereço da sua câmera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a0fef7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "O código a seguir apresenta uma captura de tela para cada uma das câmeras disponíveis e as salva no diretório atual. Abra cada figura \"camera_x_captura.jpg\" e veja o valor \"x\" correspondente à câmera que você deseja. Insira-o no próximo código em \" monitor = sct.monitors[x]\" trocando \"x\" pelo valor correspondente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94056106",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T14:10:14.991396Z",
     "start_time": "2024-03-04T14:10:12.698980Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def listar_cameras_disponiveis(max_testes=10):\n",
    "    indices_disponiveis = []\n",
    "    for i in range(max_testes):\n",
    "        cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)  # Use cv2.CAP_DSHOW para Windows\n",
    "        if cap is not None and cap.isOpened():\n",
    "            indices_disponiveis.append(i)\n",
    "            cap.release()\n",
    "    return indices_disponiveis\n",
    "\n",
    "def capturar_e_salvar_imagem_da_camera(indice_camera, nome_arquivo):\n",
    "    cap = cv2.VideoCapture(indice_camera, cv2.CAP_DSHOW)  # Use cv2.CAP_DSHOW para Windows\n",
    "    if cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            cv2.imwrite(nome_arquivo, frame)\n",
    "            print(f\"Imagem capturada e salva como {nome_arquivo}\")\n",
    "        else:\n",
    "            print(f\"Falha ao capturar imagem da câmera no índice {indice_camera}\")\n",
    "        cap.release()\n",
    "    else:\n",
    "        print(f\"Não foi possível abrir a câmera no índice {indice_camera}\")\n",
    "\n",
    "cameras_disponiveis = listar_cameras_disponiveis()\n",
    "for indice in cameras_disponiveis:\n",
    "    nome_arquivo = f\"camera_{indice}_captura.jpg\"\n",
    "    capturar_e_salvar_imagem_da_camera(indice, nome_arquivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74d9d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T13:36:44.661854Z",
     "start_time": "2024-03-04T13:36:29.474520Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!pip install mss\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59736983",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T14:14:35.573974Z",
     "start_time": "2024-03-04T14:14:20.383041Z"
    },
    "hidden": true,
    "id": "59736983",
    "outputId": "7adcbfa5-dc42-49ec-bdd7-1bcb4fb98977"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mss\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def reconhecer_imagem(img_array, modelo):\n",
    "    # Remove o canal alfa se a imagem tiver 4 canais\n",
    "    if img_array.shape[-1] == 4:\n",
    "        img_array = img_array[..., :3]\n",
    "\n",
    "    # Redimensiona para 32x32 pixels\n",
    "    img_array = cv2.resize(img_array, (32, 32))\n",
    "\n",
    "    # Converte a imagem para um array NumPy e normaliza\n",
    "    img_array = img_array / 255.0\n",
    "\n",
    "    # Expande a dimensão do array para o formato (1, 32, 32, 3)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Previsões\n",
    "    previsoes = modelo.predict(img_array)\n",
    "\n",
    "    # Obtém a classe com maior probabilidade\n",
    "    classe_prevista = np.argmax(previsoes)\n",
    "    return classe_prevista\n",
    "\n",
    "# Carrega o modelo\n",
    "modelo_reconhecimento = load_model('reconhecimento_de_imagem.h5')  # Substitua pelo nome do seu arquivo de modelo\n",
    "\n",
    "# Classes das imagens\n",
    "classes = ['Avião', 'Automóvel', 'Pássaro', 'Gato', 'Cervo', 'Cachorro', 'Sapo', 'Cavalo', 'Barco', 'Caminhão']\n",
    "\n",
    "# Inicializa o mss para captura de tela\n",
    "sct = mss.mss()\n",
    "\n",
    "while True:\n",
    "    # Captura a tela\n",
    "    monitor = sct.monitors[0]  # Modifique a depender da câmera que deseja usar.\n",
    "    frame = np.array(sct.grab(monitor))\n",
    "\n",
    "    # Processa a imagem e faz a previsão\n",
    "    classe_prevista = reconhecer_imagem(frame, modelo_reconhecimento)\n",
    "    print(\"A nova imagem foi classificada como:\", classes[classe_prevista])\n",
    "\n",
    "    # Para interromper o loop, pressione Ctrl+C no terminal\n",
    "    try:\n",
    "        cv2.waitKey(5000)  # Aguarda 1000 milissegundos\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "\n",
    "# Fecha todas as janelas abertas\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013deeb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T14:32:33.343350Z",
     "start_time": "2024-03-04T14:32:22.533130Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mss\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "# Assume-se que a função reconhecer_imagem esteja definida aqui\n",
    "\n",
    "# Carrega o modelo\n",
    "modelo_reconhecimento = load_model('reconhecimento_de_imagem.h5')\n",
    "\n",
    "# Classes das imagens\n",
    "classes = ['Avião', 'Automóvel', 'Pássaro', 'Gato', 'Cervo', 'Cachorro', 'Sapo', 'Cavalo', 'Barco', 'Caminhão']\n",
    "\n",
    "# Inicializa o mss para captura de tela\n",
    "sct = mss.mss()\n",
    "\n",
    "# Define o número de iterações\n",
    "num_iteracoes = 2  # Por exemplo, processa e exibe 5 imagens\n",
    "\n",
    "for _ in range(num_iteracoes):\n",
    "    # Captura a tela\n",
    "    monitor = sct.monitors[0]  # Ajuste conforme necessário\n",
    "    frame = np.array(sct.grab(monitor))\n",
    "\n",
    "    # Processa a imagem e faz a previsão\n",
    "    classe_prevista = reconhecer_imagem(frame, modelo_reconhecimento)\n",
    "    texto_predicao = \"A nova imagem foi classificada como: \" + classes[classe_prevista]\n",
    "\n",
    "    # Exibe o resultado\n",
    "    clear_output(wait=True)\n",
    "    print(texto_predicao)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGRA2RGB)  # Converte para RGB\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Intervalo entre as iterações para não sobrecarregar o notebook\n",
    "    time.sleep(5)  # Pausa de 2 segundos\n",
    "\n",
    "# Nota: Este loop não é infinito e permite uma execução controlada.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
